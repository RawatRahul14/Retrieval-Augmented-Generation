{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ca1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e615e",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e66aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_pipeline.components.models import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8548edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9480a905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_agent_model(\n",
    "    agent_name = \"question_rewriter\"\n",
    ").get(\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42374ca",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5658dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_pipeline.components.prompts import render_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d41201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 'ROLE\\n- You are a question rewriter for a Retrieval-Augmented Generation system.\\n\\nINPUTS\\n- \"current_question\": The user\\'s most recent query.\\n- \"conversation\": A short history of recent interactions (if available).\\n\\nTASK\\n- Rephrase the query into a clear, standalone form that captures the full intent of the user\\'s question.\\n\\nRULES\\n- Use conversation only to clarify vague references like \"this file\" or \"the previous report\".\\n- Keep the question concise and factual (under 40 tokens).\\n- Do not guess missing details; preserve ambiguity if uncertain.\\n- Avoid multi-sentence questions.',\n",
       " 'user': 'USER QUERY: What is RAG?\\nCHAT HISTORY: User: What is AI?\\nAgent: AI stands for Artificial Intelligence',\n",
       " 'output_schema': '{\\n  \"rephrased_question\": \"string\"\\n}\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_prompt(\n",
    "    prompt_name = \"question_rewriter\",\n",
    "    current_question = \"What is RAG?\",\n",
    "    conversation = \"User: What is AI?\\nAgent: AI stands for Artificial Intelligence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444914e",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e07da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import run_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a297178",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = run_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e298ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What is RAG?\"\n",
    "input_data = {\n",
    "    \"question\": user_input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb171695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is RAG?',\n",
       " 'rephrased_question': 'What does RAG stand for and what does it mean?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await graph.ainvoke(\n",
    "    input = input_data,\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"retriever\": None\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a7157d",
   "metadata": {},
   "source": [
    "### Data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3d27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_pipeline.utils.extract_doc import extract_from_pdf, extract_from_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ce5241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Reading Assignment.pdf ...\n",
      "ðŸ“„ Reading Networking Activity.pdf ...\n",
      "âœ… Extracted 4 pages and 0 tables from PDFs.\n",
      "ðŸ“„ RAG.txt: 2 chunks\n",
      "âœ… Extracted 2 text chunks from 'data'.\n"
     ]
    }
   ],
   "source": [
    "pdf_texts, pfd_tables, pdf_metadata = extract_from_pdf()\n",
    "txt_texts, txt_metadata = extract_from_text_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41dd625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'LLM Specialist Assignment\\nOverview\\nCreate a Retrieval-Augmented Generation (RAG) pipeline that allows users to upload documents and\\nask questions based on their content. The system should leverage vector databases for efficient retrieval\\nand an LLM API (e.g., OpenAI, Gemini, or another REST-based model) for generating responses. The entire\\napplication should be containerized using Docker and deployable on cloud or local environments.\\nRequirements:\\n1. Document Ingestion & Processing:\\no Support uploading up to 20 documents, each with a maximum of 1000 pages.\\no Chunk documents into manageable sizes for efficient retrieval.\\no Use text embeddings to store document chunks in a vector database (e.g., FAISS, Pinecone,\\nWeaviate, or ChromaDB).\\n2. Retrieval-Augmented Generation (RAG) Pipeline:\\no Accept user queries and retrieve relevant document chunks.\\no Pass the retrieved chunks to the LLM API for contextual response generation.\\no Ensure responses are accurate, concise, and relevant to the uploaded documents.\\n3. API & APPLICATION ARCHITECTURE:\\na. Implement a REST API using FastAPI, Flask, or Express.js.\\nb. Expose endpoints for:\\ni. Uploading documents\\nii. Querying the system\\niii. Viewing processed document metadata\\nc. Store document metadata in a relational or NoSQL database.\\n4. DEPLOYMENT & CONTAINERIZATION:\\na. Provide a Docker Compose setup with all necessary services.\\nb. Ensure seamless deployment on local machines and cloud environments (e.g., AWS,\\nGCP, Azure).',\n",
       "  'metadata': {'source': 'Assignment.pdf', 'type': 'pdf', 'page_number': 1}},\n",
       " {'content': '5. TESTING & DOCUMENTATION:\\na. Write unit and integration tests for document retrieval and query handling.\\nb. Provide a clear README.md with:\\ni. Setup and installation instructions.\\nii. API usage and testing guidelines.\\niii. Configuration details for using different LLM providers.\\nDELIVERABLES\\nâ€¢ GitHub repository with the complete source code.\\nâ€¢ Docker setup for local and cloud deployment.\\nâ€¢ Well-documented README.md with setup and API usage instructions.\\nâ€¢ Automated tests for validation.\\nâ€¢ Postman collection (optional) for testing API endpoints.\\nEVALUATION CRITERIA:\\nâ€¢ Efficiency of document retrieval and response generation.\\nâ€¢ Scalability and performance of the RAG pipeline.\\nâ€¢ Code quality, modularity, and adherence to best practices.\\nâ€¢ Ease of setup and deployment using Docker.\\nâ€¢ Thoroughness of documentation and test coverage.\\nSUBMISSION:\\nSubmit a GitHub repository link within 2 days including all deliverables.\\nYou are encouraged to submit a working demo via a publicly accessible URL. While preferred, this is not\\nmandatory.',\n",
       "  'metadata': {'source': 'Assignment.pdf', 'type': 'pdf', 'page_number': 2}},\n",
       " {'content': 'Networking Activity\\nIndividual Submission\\nObjective\\nThis activity encourages WIL employees to apply the networking strategies discussed in the\\nprofessional development session in week seven (Networking for Career Success). The goal is to\\nreflect on their experiences at a networking event and demonstrate how they will build long-\\nterm connections beyond the WIL project.\\nInstructions\\nPart One: Attend a Networking Event\\nWIL employees must select and attend a networking event related to your field of interest. This\\neven can be in-person or virtual.\\nâ€¢ *Evidence of Attendance: WIL employees must provide proof of ticket purchase or\\nregistration. In addition to the proof of ticket purchase or registration you must take a\\nscreenshot of yourself attending if the event was online, or a picture of you at the event\\nif it was in person.\\nPart Two: Reflection\\nAfter attending the event, you are expected to submit a one-page reflection. This reflection is\\nnot just about sending a follow-up message but about crafting a thoughtful, long-term\\nnetworking plan. Take this opportunity to reflect on how you can leverage the relationships you\\nbuild during WIL to further your career goals.\\nThe reflection should be formatted as follows:\\nNetworking Activity | 1\\n*If the images provided are not clear, it will result in an automatic failure with no exceptions.',\n",
       "  'metadata': {'source': 'Networking Activity.pdf',\n",
       "   'type': 'pdf',\n",
       "   'page_number': 1}},\n",
       " {'content': 'â€¢ Introduction: Briefly describe the event, including its purpose and the key professionals\\nor organizations you interacted with.\\nâ€¢ Networking Strategies Applied: Discuss how you utilized the networking strategies from\\nthe professional development session. Mention specific actions, such as conversation\\nstarters, active listening, or personalized follow-ups.\\nâ€¢ Relationship Building Beyond WIL: Reflect on how you plan to maintain and grow these\\nnew connections beyond the WIL program. Provide examples (e.g., LinkedIn\\nengagement, scheduling follow-up meetings, attending future events).\\nâ€¢ Successes & Challenges: Highlight what worked well during the event and identify areas\\nfor improvement and what you would do differently next time (e.g., preparing better\\nquestions or being more proactive).\\nFormatting & Submission Guidelines\\nâ€¢ Length: 1 page (2 max if needed), double-spaced. No cover page or reference needed â€“\\nthis is a reflection.\\nâ€¢ File Format: PDF or Word document.\\nâ€¢ *Proof of Attendance: Attach the screenshot/picture of yourself attending and\\nticket/registration proof.\\nNetworking Activity | 2\\n*If the images provided are not clear, it will result in an automatic failure with no exceptions.',\n",
       "  'metadata': {'source': 'Networking Activity.pdf',\n",
       "   'type': 'pdf',\n",
       "   'page_number': 2}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc5b6084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'Assignment.pdf',\n",
       "  'file_path': 'C:\\\\Users\\\\rahul\\\\Desktop\\\\Coding Assignment\\\\Retrieval-Augmented-Generation\\\\data\\\\Assignment.pdf',\n",
       "  'type': 'pdf',\n",
       "  'size_kb': 84.35,\n",
       "  'total_pages': 2,\n",
       "  'total_tables': 0},\n",
       " {'file_name': 'Networking Activity.pdf',\n",
       "  'file_path': 'C:\\\\Users\\\\rahul\\\\Desktop\\\\Coding Assignment\\\\Retrieval-Augmented-Generation\\\\data\\\\Networking Activity.pdf',\n",
       "  'type': 'pdf',\n",
       "  'size_kb': 215.3,\n",
       "  'total_pages': 2,\n",
       "  'total_tables': 0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943aec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'RAG.txt',\n",
       "  'file_path': 'C:\\\\Users\\\\rahul\\\\Desktop\\\\Coding Assignment\\\\Retrieval-Augmented-Generation\\\\data\\\\RAG.txt',\n",
       "  'type': 'text',\n",
       "  'size_kb': 0.66,\n",
       "  'total_chunks': 2}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685a1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_texts.extend(txt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94564f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'LLM Specialist Assignment\\nOverview\\nCreate a Retrieval-Augmented Generation (RAG) pipeline that allows users to upload documents and\\nask questions based on their content. The system should leverage vector databases for efficient retrieval\\nand an LLM API (e.g., OpenAI, Gemini, or another REST-based model) for generating responses. The entire\\napplication should be containerized using Docker and deployable on cloud or local environments.\\nRequirements:\\n1. Document Ingestion & Processing:\\no Support uploading up to 20 documents, each with a maximum of 1000 pages.\\no Chunk documents into manageable sizes for efficient retrieval.\\no Use text embeddings to store document chunks in a vector database (e.g., FAISS, Pinecone,\\nWeaviate, or ChromaDB).\\n2. Retrieval-Augmented Generation (RAG) Pipeline:\\no Accept user queries and retrieve relevant document chunks.\\no Pass the retrieved chunks to the LLM API for contextual response generation.\\no Ensure responses are accurate, concise, and relevant to the uploaded documents.\\n3. API & APPLICATION ARCHITECTURE:\\na. Implement a REST API using FastAPI, Flask, or Express.js.\\nb. Expose endpoints for:\\ni. Uploading documents\\nii. Querying the system\\niii. Viewing processed document metadata\\nc. Store document metadata in a relational or NoSQL database.\\n4. DEPLOYMENT & CONTAINERIZATION:\\na. Provide a Docker Compose setup with all necessary services.\\nb. Ensure seamless deployment on local machines and cloud environments (e.g., AWS,\\nGCP, Azure).',\n",
       "  'metadata': {'source': 'Assignment.pdf', 'type': 'pdf', 'page_number': 1}},\n",
       " {'content': '5. TESTING & DOCUMENTATION:\\na. Write unit and integration tests for document retrieval and query handling.\\nb. Provide a clear README.md with:\\ni. Setup and installation instructions.\\nii. API usage and testing guidelines.\\niii. Configuration details for using different LLM providers.\\nDELIVERABLES\\nâ€¢ GitHub repository with the complete source code.\\nâ€¢ Docker setup for local and cloud deployment.\\nâ€¢ Well-documented README.md with setup and API usage instructions.\\nâ€¢ Automated tests for validation.\\nâ€¢ Postman collection (optional) for testing API endpoints.\\nEVALUATION CRITERIA:\\nâ€¢ Efficiency of document retrieval and response generation.\\nâ€¢ Scalability and performance of the RAG pipeline.\\nâ€¢ Code quality, modularity, and adherence to best practices.\\nâ€¢ Ease of setup and deployment using Docker.\\nâ€¢ Thoroughness of documentation and test coverage.\\nSUBMISSION:\\nSubmit a GitHub repository link within 2 days including all deliverables.\\nYou are encouraged to submit a working demo via a publicly accessible URL. While preferred, this is not\\nmandatory.',\n",
       "  'metadata': {'source': 'Assignment.pdf', 'type': 'pdf', 'page_number': 2}},\n",
       " {'content': 'Networking Activity\\nIndividual Submission\\nObjective\\nThis activity encourages WIL employees to apply the networking strategies discussed in the\\nprofessional development session in week seven (Networking for Career Success). The goal is to\\nreflect on their experiences at a networking event and demonstrate how they will build long-\\nterm connections beyond the WIL project.\\nInstructions\\nPart One: Attend a Networking Event\\nWIL employees must select and attend a networking event related to your field of interest. This\\neven can be in-person or virtual.\\nâ€¢ *Evidence of Attendance: WIL employees must provide proof of ticket purchase or\\nregistration. In addition to the proof of ticket purchase or registration you must take a\\nscreenshot of yourself attending if the event was online, or a picture of you at the event\\nif it was in person.\\nPart Two: Reflection\\nAfter attending the event, you are expected to submit a one-page reflection. This reflection is\\nnot just about sending a follow-up message but about crafting a thoughtful, long-term\\nnetworking plan. Take this opportunity to reflect on how you can leverage the relationships you\\nbuild during WIL to further your career goals.\\nThe reflection should be formatted as follows:\\nNetworking Activity | 1\\n*If the images provided are not clear, it will result in an automatic failure with no exceptions.',\n",
       "  'metadata': {'source': 'Networking Activity.pdf',\n",
       "   'type': 'pdf',\n",
       "   'page_number': 1}},\n",
       " {'content': 'â€¢ Introduction: Briefly describe the event, including its purpose and the key professionals\\nor organizations you interacted with.\\nâ€¢ Networking Strategies Applied: Discuss how you utilized the networking strategies from\\nthe professional development session. Mention specific actions, such as conversation\\nstarters, active listening, or personalized follow-ups.\\nâ€¢ Relationship Building Beyond WIL: Reflect on how you plan to maintain and grow these\\nnew connections beyond the WIL program. Provide examples (e.g., LinkedIn\\nengagement, scheduling follow-up meetings, attending future events).\\nâ€¢ Successes & Challenges: Highlight what worked well during the event and identify areas\\nfor improvement and what you would do differently next time (e.g., preparing better\\nquestions or being more proactive).\\nFormatting & Submission Guidelines\\nâ€¢ Length: 1 page (2 max if needed), double-spaced. No cover page or reference needed â€“\\nthis is a reflection.\\nâ€¢ File Format: PDF or Word document.\\nâ€¢ *Proof of Attendance: Attach the screenshot/picture of yourself attending and\\nticket/registration proof.\\nNetworking Activity | 2\\n*If the images provided are not clear, it will result in an automatic failure with no exceptions.',\n",
       "  'metadata': {'source': 'Networking Activity.pdf',\n",
       "   'type': 'pdf',\n",
       "   'page_number': 2}},\n",
       " {'content': 'Retrieval-Augmented Generation (RAG) combines retrieval and generation to improve the factual accuracy of language models. It works by fetching relevant information from external sources such as documents or databases, then using that information to generate more accurate and context-aware responses.',\n",
       "  'metadata': {'source': 'RAG.txt', 'type': 'text', 'chunk_id': 1}},\n",
       " {'content': 'A typical RAG system includes three main components:\\n1. A retriever that searches and fetches relevant chunks.\\n2. A generator (usually an LLM) that uses the retrieved data to answer questions.\\n3. A vector database like FAISS that stores embeddings for quick semantic search. This approach reduces hallucinations and enhances the reliability of LLM-based systems.',\n",
       "  'metadata': {'source': 'RAG.txt', 'type': 'text', 'chunk_id': 2}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0b2b1",
   "metadata": {},
   "source": [
    "### Data Extract Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4d0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_pipeline.pipeline.data_extract import extract_data_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbda341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Reading Assignment.pdf ...\n",
      "ðŸ“„ Reading Networking Activity.pdf ...\n",
      "âœ… Extracted 4 pages and 0 tables from PDFs.\n",
      "ðŸ“„ RAG.txt: 2 chunks\n",
      "âœ… Extracted 2 text chunks from 'data'.\n",
      "âœ… Combined 6 text chunks from 3 files.\n"
     ]
    }
   ],
   "source": [
    "texts, tables, metadata = extract_data_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fe031",
   "metadata": {},
   "source": [
    "### retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33188678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_pipeline.components.retriever import create_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741fbec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š Preparing 6 documents for indexing...\n",
      "âœ… Retriever (FAISS index) created and saved at: ./models/faiss_index\n"
     ]
    }
   ],
   "source": [
    "db, path = create_retriever(\n",
    "    texts = texts,\n",
    "    tables = tables,\n",
    "    model_name = \"text-embedding-3-small\",\n",
    "    save_path = \"./models/faiss_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89c83a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='aab8287d-356c-4fc7-9828-b7105f40ad94', metadata={'source': 'RAG.txt', 'type': 'text', 'chunk_id': 1}, page_content='Retrieval-Augmented Generation (RAG) combines retrieval and generation to improve the factual accuracy of language models. It works by fetching relevant information from external sources such as documents or databases, then using that information to generate more accurate and context-aware responses.'),\n",
       " Document(id='f4b985ec-21e4-4591-9891-247d37690cb4', metadata={'source': 'RAG.txt', 'type': 'text', 'chunk_id': 2}, page_content='A typical RAG system includes three main components:\\n1. A retriever that searches and fetches relevant chunks.\\n2. A generator (usually an LLM) that uses the retrieved data to answer questions.\\n3. A vector database like FAISS that stores embeddings for quick semantic search. This approach reduces hallucinations and enhances the reliability of LLM-based systems.'),\n",
       " Document(id='b452ef9f-954b-4efc-8779-fd47b6d124ed', metadata={'source': 'Assignment.pdf', 'type': 'pdf', 'page_number': 2}, page_content='5. TESTING & DOCUMENTATION:\\na. Write unit and integration tests for document retrieval and query handling.\\nb. Provide a clear README.md with:\\ni. Setup and installation instructions.\\nii. API usage and testing guidelines.\\niii. Configuration details for using different LLM providers.\\nDELIVERABLES\\nâ€¢ GitHub repository with the complete source code.\\nâ€¢ Docker setup for local and cloud deployment.\\nâ€¢ Well-documented README.md with setup and API usage instructions.\\nâ€¢ Automated tests for validation.\\nâ€¢ Postman collection (optional) for testing API endpoints.\\nEVALUATION CRITERIA:\\nâ€¢ Efficiency of document retrieval and response generation.\\nâ€¢ Scalability and performance of the RAG pipeline.\\nâ€¢ Code quality, modularity, and adherence to best practices.\\nâ€¢ Ease of setup and deployment using Docker.\\nâ€¢ Thoroughness of documentation and test coverage.\\nSUBMISSION:\\nSubmit a GitHub repository link within 2 days including all deliverables.\\nYou are encouraged to submit a working demo via a publicly accessible URL. While preferred, this is not\\nmandatory.'),\n",
       " Document(id='f43a64fb-91c5-4110-b206-c50ede03278f', metadata={'source': 'Assignment.pdf', 'type': 'pdf', 'page_number': 1}, page_content='LLM Specialist Assignment\\nOverview\\nCreate a Retrieval-Augmented Generation (RAG) pipeline that allows users to upload documents and\\nask questions based on their content. The system should leverage vector databases for efficient retrieval\\nand an LLM API (e.g., OpenAI, Gemini, or another REST-based model) for generating responses. The entire\\napplication should be containerized using Docker and deployable on cloud or local environments.\\nRequirements:\\n1. Document Ingestion & Processing:\\no Support uploading up to 20 documents, each with a maximum of 1000 pages.\\no Chunk documents into manageable sizes for efficient retrieval.\\no Use text embeddings to store document chunks in a vector database (e.g., FAISS, Pinecone,\\nWeaviate, or ChromaDB).\\n2. Retrieval-Augmented Generation (RAG) Pipeline:\\no Accept user queries and retrieve relevant document chunks.\\no Pass the retrieved chunks to the LLM API for contextual response generation.\\no Ensure responses are accurate, concise, and relevant to the uploaded documents.\\n3. API & APPLICATION ARCHITECTURE:\\na. Implement a REST API using FastAPI, Flask, or Express.js.\\nb. Expose endpoints for:\\ni. Uploading documents\\nii. Querying the system\\niii. Viewing processed document metadata\\nc. Store document metadata in a relational or NoSQL database.\\n4. DEPLOYMENT & CONTAINERIZATION:\\na. Provide a Docker Compose setup with all necessary services.\\nb. Ensure seamless deployment on local machines and cloud environments (e.g., AWS,\\nGCP, Azure).')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"What is RAG?\", k = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
